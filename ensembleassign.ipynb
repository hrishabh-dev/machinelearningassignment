{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2122310e-9659-4541-92f8-893d47cdad2d",
   "metadata": {},
   "source": [
    "# Theoretical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeec9d76-96a1-4606-91be-b4f063d387ee",
   "metadata": {},
   "source": [
    "### 1  Can we use Bagging for regression problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faa6193-1604-45d1-9684-c9025da6c036",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " bagging (Bootstrap Aggregating) can be used for regression problems as \n",
    " well as classification problems. \n",
    " \n",
    " In regression, bagging involves creating multiple bootstrapped subsets of the \n",
    " training data, training  a regression model on each subset, and\n",
    " then aggregating the predictions to produce a final result.\n",
    "\n",
    "\n",
    "Bagging is the basis for well-known ensemble methods like Random Forests, which also use multiple\n",
    "decision trees to improve predictive performance.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a92fd4-5c6e-4197-becc-89623906c7e3",
   "metadata": {},
   "source": [
    "### 2  What is the difference between multiple model training and single model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82991991-fd20-40cf-8b4a-4d0c3c18ddd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Single Model Training\n",
    "\n",
    "Single model training involves training one model on the entire dataset to make predictions.\n",
    "\n",
    "A single algorithm is applied to the dataset.\n",
    "\n",
    "The training process focuses on optimizing the model parameters based on the available data.\n",
    "\n",
    "A single model may learn noise in the training data, especially if it is complex.\n",
    "\n",
    "Multiple Model Training \n",
    "\n",
    " Multiple model training refers to the process of building several models \n",
    " and combining their predictions to improve overall performance.\n",
    "\n",
    "Techniques like bagging, boosting, and stacking are used.\n",
    "\n",
    "Each model is trained separately, often on different subsets of the data or\n",
    "with different starting conditions or parameters.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcda32fe-4e32-40e9-a0c1-791f96ca3cf2",
   "metadata": {},
   "source": [
    "### 3  Explain the concept of feature randomness in Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5646d40-8f99-4b72-a920-b46dd9130756",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "It is an ensemble learning method primarily used for classification and regression tasks\n",
    "This concept contributes significantly to the model's robustness and helps prevent overfitting.\n",
    "\n",
    "\n",
    "When training each decision tree in the Random Forest, a random sample of the training\n",
    "data is drawn. \n",
    "\n",
    "Then, for each split in the tree, a random subset of features is \n",
    "selected from the total features available.\n",
    "\n",
    "enabling it to create multiple diverse decision trees that, when combined, can \n",
    " make more accurate and reliable predictions\n",
    "\n",
    " the best split is chosen based on a certain criterion . \n",
    " \n",
    " This process ensures that different trees in the forest are constructed using \n",
    " different features and samples.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba043fc-f023-418d-9c01-ff19fc03e671",
   "metadata": {},
   "source": [
    "### 4 What is OOB (Out-of-Bag) Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9883e1d5-fae4-4556-aed8-6c24f3bd630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " Out-of-Bag (OOB) score is a performance metric specific to ensemble learning methods \n",
    " like Random Forests. \n",
    " \n",
    " It provides an estimate of the model's accuracy on unseen data without \n",
    " the need to use a separate validation set\n",
    "\n",
    " about one-third of the training samples are left out (not included) in each bootstrapped sample.\n",
    " These unused samples are known as the Out-of-Bag samples.\n",
    "\n",
    "  It maximizes the use of available data, provides reliability in performance estimation, and\n",
    "  offers insights into the model's predictive capabilities\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780c74a0-e537-4de5-8cc6-b80622c5a2cf",
   "metadata": {},
   "source": [
    "### 5  How can you measure the importance of features in a Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272fb68c-8cf9-49b3-a441-04b355ae807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "There are several methods to evaluate feature importance, each with its strengths\n",
    "\n",
    "Mean Decrease Impurity (MDI) / Gini Importance\n",
    "\n",
    "As trees are built, each time a node is split using a feature, the algorithm \n",
    "calculates the reduction in impurity  that results from that split.\n",
    "\n",
    "Mean Decrease Accuracy (MDA)\n",
    "\n",
    "This method evaluates the importance of each feature by measuring how much the accuracy \n",
    "of the model decreases when the feature's values are permuted \n",
    "\n",
    "Tree Structures\n",
    "\n",
    "This method utilizes the structure of the trees formed in the Random Forest,\n",
    "specifically looking at how often a feature is used to make decisions in the trees.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b891a280-2995-4768-973c-c1ae037c4f72",
   "metadata": {},
   "source": [
    "### 6  Explain the working principle of a Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d145aee-fa6f-44e5-b0bb-5f731e35b5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "\n",
    "Bagging starts by creating multiple subsets of the original training dataset.\n",
    "\n",
    "Each subset is created through a process known as bootstrapping, which involves\n",
    "sampling with replacement.\n",
    "\n",
    "for each subset, some instances may be selected multiple times while others may be left out.\n",
    "\n",
    "Independent Model Training\n",
    "\n",
    "A separate and independent model is trained on each bootstrap sample.\n",
    "\n",
    "This means that the models are trained on different data, leading to variability \n",
    "in their predictions.\n",
    "\n",
    "Once all models have been trained, predictions are made for new data points. \n",
    "\n",
    "The final prediction of the Bagging classifier is aggregated from the predictions\n",
    "of all individual models.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1015ef08-cac9-4b12-a099-9b49416edc0c",
   "metadata": {},
   "source": [
    "### 7 How do you evaluate a Bagging Classifier’s performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02870d34-023c-4263-8990-7d01b9395a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "we  can evaluate its performance using various metrics\n",
    "\n",
    "For Classification Tasks\n",
    "\n",
    "Accuracy\n",
    "Proportion of correct predictions out of all predictions.\n",
    "\n",
    "Precision\n",
    "The ratio of true positive predictions to the total predicted positives.\n",
    "\n",
    "Recall (Sensitivity)\n",
    "The ratio of true positive predictions to the actual positives. \n",
    "\n",
    "F1 Score\n",
    "The harmonic mean of precision and recall.\n",
    "\n",
    "Confusion Matrix\n",
    "A table used to describe the performance of a classification model\n",
    "\n",
    "ROC Curve and AUC\n",
    "The ROC curve shows the true positive rate against the false positive \n",
    "rate at various threshold settings.\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a66139-bdcf-4986-bd02-6f275da410ae",
   "metadata": {},
   "source": [
    "### 8 How does a Bagging Regressor work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c78afae-bc33-40cf-a8fa-08054a667536",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "\n",
    "Bagging helps improve the robustness and accuracy of regression models\n",
    "by combining the predictions of multiple models trained on different \n",
    "subsets of the training data\n",
    "\n",
    "The process begins with generating multiple bootstrap samples of the training data.\n",
    "\n",
    "A bootstrap sample is created by randomly selecting instances from the original dataset\n",
    "with replacement. \n",
    "\n",
    "For each bootstrap sample, a separate regression model is trained. \n",
    "\n",
    "Bagging Regressors are more robust to outliers and noise in the\n",
    "training data compared to a single model\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb433717-b9aa-4552-9a72-77fed6718b12",
   "metadata": {},
   "source": [
    "### 9  What is the main advantage of ensemble techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec17e95-9284-45f1-8f42-0d4c6075672b",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    " The main advantages of ensemble techniques include:\n",
    "\n",
    "1. Improved Accuracy\n",
    "2. Better Generalization\n",
    "3. Robustness to Noise and Outliers\n",
    "4. Improved Stability\n",
    "5. Flexibility\n",
    "6. Enhanced Predictions\n",
    "7. Adaptability\n",
    "\n",
    "By reducing error, improving generalization, increasing robustness, and providing \n",
    "more stable predictions, ensemble methods have become essential tools in modern\n",
    "machine learning, driving advances across many applications and domains.\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c5b726-9736-4b81-bd22-4efb90a3ad82",
   "metadata": {},
   "source": [
    "### 10 What is the main challenge of ensemble methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818c350e-6855-44d1-8592-86e7f8cbd810",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Ensemble methods often require training multiple models, which can be significantly \n",
    "more computationally intensive and \n",
    "time-consuming than training a single model.\n",
    "\n",
    "\n",
    "More resources (CPU/GPU memory and processing power) are required to manage multiple models\n",
    "\n",
    "Ensembles can be more challenging to interpret than individual models.\n",
    "\n",
    "\n",
    "The complexity of the model can make it difficult to diagnose problems,\n",
    "perform debugging, or understand the role of individual predictors in the ensemble.\n",
    "\n",
    "\n",
    " ensemble methods can reduce overfitting by averaging predictions, they can still \n",
    " overfit if the individual models are too complex\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69838a3c-b069-4b58-9d4b-b46d53aacd65",
   "metadata": {},
   "source": [
    "### 11 Explain the key idea behind ensemble techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7cf5c4-ce67-4290-b6e6-0aa1a7e11dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "The key idea behind ensemble techniques in machine learning is to combine\n",
    "multiple models, or \"learners,\" to produce a single, more robust model that\n",
    "improves predictive performance compared to any individual model alone\n",
    "\n",
    "the ensemble often reduces variance, bias, or both, leading to better generalization on unseen data.\n",
    "\n",
    "This works on the principle that diverse models can complement each other's strengths\n",
    "and weaknesses, resulting in a more accurate and reliable predictive model.\n",
    "\n",
    "ensembles can effectively average out errors and reduce the impact of outliers\n",
    "or noise in the dataset\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687690dc-7884-41ce-bfc2-158c1fa587f8",
   "metadata": {},
   "source": [
    "### 12  What is a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628dc63e-05f9-42ad-8737-c9a31d267023",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "\n",
    "A Random Forest Classifier is an ensemble learning method that is\n",
    "used for classification tasks.\n",
    "\n",
    "It consists of multiple decision trees built on different subsets of the \n",
    "training data, using a technique called bagging\n",
    "\n",
    "\n",
    "Each tree in the forest votes for a class label, and the final output is determined by the\n",
    "majority vote of all the trees\n",
    "\n",
    "\n",
    "Random Forest Classifiers can handle large datasets with high dimensionality and are\n",
    "robust against noise and outliers, making them a popular choice for diverse applications \n",
    "in machine learning.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b17194a-08d8-458d-b30c-d29d6baa0c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "we can import the Random Forest Classifier from the sklearn (scikit-learn) library \n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1867a369-25de-426f-8d5e-43aacd252bd7",
   "metadata": {},
   "source": [
    "### 13 What are the main types of ensemble techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf676f53-3da5-4d64-b072-b9995408dc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "\n",
    "Bagging (Bootstrap Aggregating): Combines predictions from multiple models \n",
    "trained on different subsets of the training data. \n",
    "\n",
    "The most common example is the Random Forest\n",
    "\n",
    "\n",
    "Boosting: Sequentially builds models, where each new model focuses on correcting \n",
    "errors made by previous ones.\n",
    "\n",
    "This approach aims to improve the overall performance.\n",
    "\n",
    "\n",
    "Stacking: Involves training multiple base learners and then using another model\n",
    "(the meta-learner) to combine their predictions. \n",
    "\n",
    "This technique can leverage various algorithms to enhance predictive power.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a37b526-9ff2-4e1a-9208-cfbc9edf8a3a",
   "metadata": {},
   "source": [
    "### 14 What is ensemble learning in machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf85cc20-3553-4cf9-8ab1-60378526837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Ensemble learning is a machine learning technique that combines multiple \n",
    "models to improve the overall performance and robustness of predictions.\n",
    "\n",
    "By aggregating the outputs of various algorithms—often referred to as \n",
    "\"base learners\"—ensemble methods aim to reduce errors, enhance accuracy, and \n",
    "minimize overfitting. \n",
    "\n",
    "The main approaches include bagging, boosting, and stacking, each leveraging the \n",
    "strengths of individual models to create a more powerful and reliable ensemble model.\n",
    "\n",
    "ultimately leading to better generalization on unseen data.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9213f5-1de7-4f98-8f10-75cd7983811e",
   "metadata": {},
   "source": [
    "### 15 When should we avoid using ensemble methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afa85c7-05b4-405a-8e66-ace5b3defe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''  \n",
    "\n",
    " When dealing with small datasets, simpler models may perform better as \n",
    " ensemble methods can lead to increased complexity without sufficient data to support them.\n",
    "\n",
    " If quick inference times are crucial, the added computational overhead of\n",
    " ensemble methods may be a drawback, as they often require aggregating multiple models.\n",
    "\n",
    " In cases where model interpretability is essential, such as in healthcare or finance, \n",
    " simpler, single models are preferable\n",
    "\n",
    "When the data does not exhibit significant variance or complexity, simpler models may \n",
    "suffice, making the additional complexity of ensembles unnecessary.\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fd4d8e-033f-4a1c-98a1-c5b8b6e64823",
   "metadata": {},
   "source": [
    "### 16 How does Bagging help in reducing overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22e054e-0e80-49a1-87cf-9b0f515e8f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "\n",
    "Bagging helps reduce overfitting by training multiple models on different \n",
    "subsets of the training data and then averaging their predictions. \n",
    "\n",
    "\n",
    "It works by creating multiple bootstrap samples—random samples with replacement—from the\n",
    "original dataset, allowing each model to learn from a varied representation of the data.\n",
    "\n",
    "\n",
    "This diversity among the models helps to smooth out the individual\n",
    "model's idiosyncrasies, thereby reducing\n",
    "variance and the likelihood of overfitting.\n",
    "\n",
    " the overall ensemble model becomes more stable and generalizes better to unseen data.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "583f4289-895b-42d0-b2e4-cb9dd6c1a84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bagging Classifier: 1.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "base_model = DecisionTreeClassifier()\n",
    "bagging_model = BaggingClassifier(estimator=base_model, n_estimators=50, random_state=42)\n",
    "bagging_model.fit(X_train, y_train)\n",
    "y_pred = bagging_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy of Bagging Classifier: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c98e894-74ad-457f-95d6-81337861dd9e",
   "metadata": {},
   "source": [
    "### 17 Why is Random Forest better than a single Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907684f3-e149-40ee-b9db-23d858a8c3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "A single Decision Tree can easily overfit the training data by capturing\n",
    "noise and specific patterns in the data.\n",
    "\n",
    "\n",
    "Random Forest mitigates this by averaging the results from multiple trees, which \n",
    "helps generalize better to unseen data.\n",
    "\n",
    "\n",
    " Random Forest builds each tree on a random subset of the data and uses a\n",
    " random subset of features for splitting at each node.\n",
    "\n",
    " \n",
    " This introduces variability among the trees, making the ensemble\n",
    " more resilient against biases that might affect individual trees.\n",
    "\n",
    "\n",
    "  The ensemble nature of Random Forest makes it less sensitive to outliers\n",
    "  and noise in the data, as the effect of any single model can be \n",
    "  diminished by the majority vote or average.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75adde8-edd2-4f06-8982-1f67e1056367",
   "metadata": {},
   "source": [
    "### 18 What is the role of bootstrap sampling in Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ab0212-8948-4da4-bb0e-9093fa350682",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "\n",
    "Bootstrap sampling involves drawing random samples from the training \n",
    "dataset with replacement. \n",
    "\n",
    "\n",
    "This means that some observations may appear multiple times in a \n",
    "given sample, while others could be omitted altogether.\n",
    "\n",
    "\n",
    " Each model in the Bagging ensemble is trained on a different bootstrap \n",
    " sample, leading to variability among the models. \n",
    "\n",
    "\n",
    " By using different subsets for training each model, Bagging reduces\n",
    " the variance of the predictions.\n",
    "\n",
    "The averaging of predictions from multiple models trained on \n",
    "diverse samples typically results in better performance in terms of accuracy and robustness\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c32423-9360-4a46-927f-3a46f5403b3e",
   "metadata": {},
   "source": [
    "### 19 What are some real-world applications of ensemble techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf8a01e-84e0-47d3-8a09-f00347292475",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "In credit scoring and risk assessment, ensemble methods like Random Forests and Gradient Boosting \n",
    "are employed to predict borrower defaults\n",
    "\n",
    "Ensemble models are used for disease diagnosis and prognosis, such as predicting\n",
    "patient outcomes or disease progression\n",
    "\n",
    "In customer segmentation and churn prediction, ensemble techniques help businesses\n",
    "analyze consumer behavior and preference\n",
    "\n",
    "Ensemble methods are applied in computer vision and natural language processing,\n",
    "improving the accuracy of tasks \n",
    "\n",
    " Financial institutions use ensemble techniques to identify fraudulent transactions\n",
    " by analyzing patterns in transaction data, allowing them to flag suspicious activities more effectively.\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f593e78e-23e2-4173-be3d-c8400b21636e",
   "metadata": {},
   "source": [
    "### 20 What is the difference between Bagging and Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3129765-01b9-479e-a2b7-8e2d2eae24e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''   \n",
    "in bagging, multiple models are trained independently from different bootstrap \n",
    "samples of the dataset .\n",
    "\n",
    "Each model is trained without regard to the performance of others. \n",
    "\n",
    "The final prediction is typically made by averaging (for regression tasks) or\n",
    "voting  the predictions of all models.\n",
    "\n",
    "Models are built independently of each other, which reduces variance\n",
    "by averaging out the predictions.\n",
    "\n",
    "Primarily reduces variance, making it suitable for high-variance models, like decision trees\n",
    "\n",
    " In boosting, models are trained sequentially, where each new model focuses on the \n",
    " errors made by the previous ones. \n",
    " \n",
    " The idea is to give more weight to misclassified instances, allowing \n",
    " the ensemble to progressively correct its mistakes.\n",
    " \n",
    " The final prediction is a weighted combination of the predictions of all models.\n",
    "\n",
    " Models are dependent on one another, with each model aiming to\n",
    " improve upon the previous one, resulting\n",
    " in a sequential chain of learning.\n",
    "\n",
    " Aims to reduce both bias and variance, making it effective for various\n",
    " types of models, especially when focusing on complex relationships in the data.\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9e22dc-e6a3-45de-9730-578b0f5fda5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e85a8c5-c84c-42dc-8388-c8cb3a112e3c",
   "metadata": {},
   "source": [
    "# Practical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58041544-05a1-435a-b949-884cc582e71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import BaggingRegressor \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e38469f-f321-4b9a-bc14-155ce69c7065",
   "metadata": {},
   "source": [
    "### 21 Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5b7a2d9-8a4f-49a3-b647-6dd53d72871a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e764165-6dd7-4619-baa9-735ff0683391",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=make_classification(n_samples=1000,n_features=10,n_classes=2)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e907411-d090-4fac-ade5-863ff27d5d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree=DecisionTreeClassifier()\n",
    "bg=BaggingClassifier(estimator=tree,n_estimators=100,random_state=2) \n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ddbea54-abb4-4c53-a25d-714fa5dbf4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bg.fit(x_train,y_train) \n",
    "y_pred=bg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8ed6cb6-75fb-4812-9717-dd665e72b143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33d210fe-aa82-4a42-a2fb-40f5e8b33063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :- 0.97\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy :-\",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3842b8f3-bfbd-4918-996a-42c6759b6296",
   "metadata": {},
   "source": [
    "### 22 Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2eb5cce-1b9e-44fb-a0d3-8f0611dd45e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression \n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cde38e71-9476-4df3-890f-2389c0b98413",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=make_regression(n_samples=1000,n_features=10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ee8534e-56da-4b07-95be-4ee8334063b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree=DecisionTreeRegressor() \n",
    "bg=BaggingRegressor(estimator=tree,n_estimators=100,random_state=2) \n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e7b7d24-9a77-41c2-a4e2-13b3ae0a9b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "bg.fit(x_train,y_train) \n",
    "y_pred=bg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2d11ab1-f4e8-4882-b5a2-01568dc80890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:- 4465.755214449835\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"MSE:-\",mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead20130-70f1-4d08-b301-68b3eb12d925",
   "metadata": {},
   "source": [
    "### 23  Train a Random Forest Classifier on the Breast Cancer dataset and print feature importance scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4714075c-a142-4bb0-b741-41f72d10dc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be9dc5c4-6c6a-40bd-b31c-26692034d595",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=load_breast_cancer()\n",
    "x=c.data\n",
    "y=c.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed318a17-3d10-41e2-b345-2cf189820e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83f6746b-1e72-49e2-9184-0c0598ccd810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestClassifier()\n",
    "rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c10cecaa-2af5-4a0d-b799-f4d9dfffef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69ad7991-7928-4326-b299-9001e4dde9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi=rf.feature_importances_ \n",
    "cc=c.feature_names \n",
    "feature_importance_df=pd.DataFrame({'Feature': cc, 'Importance': fi})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48a5660f-7c8f-4c80-a73f-40d700ed4122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean radius</td>\n",
       "      <td>0.040681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean texture</td>\n",
       "      <td>0.014282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean perimeter</td>\n",
       "      <td>0.040795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mean area</td>\n",
       "      <td>0.060686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mean smoothness</td>\n",
       "      <td>0.004907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mean compactness</td>\n",
       "      <td>0.011406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mean concavity</td>\n",
       "      <td>0.037105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mean concave points</td>\n",
       "      <td>0.099817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mean symmetry</td>\n",
       "      <td>0.003331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mean fractal dimension</td>\n",
       "      <td>0.004772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>radius error</td>\n",
       "      <td>0.020111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>texture error</td>\n",
       "      <td>0.006158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>perimeter error</td>\n",
       "      <td>0.012499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>area error</td>\n",
       "      <td>0.047024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>smoothness error</td>\n",
       "      <td>0.003511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>compactness error</td>\n",
       "      <td>0.005254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>concavity error</td>\n",
       "      <td>0.003028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>concave points error</td>\n",
       "      <td>0.010300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>symmetry error</td>\n",
       "      <td>0.002488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fractal dimension error</td>\n",
       "      <td>0.004129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>worst radius</td>\n",
       "      <td>0.091616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>worst texture</td>\n",
       "      <td>0.023959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>worst perimeter</td>\n",
       "      <td>0.140268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>worst area</td>\n",
       "      <td>0.109944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>worst smoothness</td>\n",
       "      <td>0.012964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>worst compactness</td>\n",
       "      <td>0.021098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>worst concavity</td>\n",
       "      <td>0.028202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>worst concave points</td>\n",
       "      <td>0.121761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>worst symmetry</td>\n",
       "      <td>0.010522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>worst fractal dimension</td>\n",
       "      <td>0.007382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Feature  Importance\n",
       "0               mean radius    0.040681\n",
       "1              mean texture    0.014282\n",
       "2            mean perimeter    0.040795\n",
       "3                 mean area    0.060686\n",
       "4           mean smoothness    0.004907\n",
       "5          mean compactness    0.011406\n",
       "6            mean concavity    0.037105\n",
       "7       mean concave points    0.099817\n",
       "8             mean symmetry    0.003331\n",
       "9    mean fractal dimension    0.004772\n",
       "10             radius error    0.020111\n",
       "11            texture error    0.006158\n",
       "12          perimeter error    0.012499\n",
       "13               area error    0.047024\n",
       "14         smoothness error    0.003511\n",
       "15        compactness error    0.005254\n",
       "16          concavity error    0.003028\n",
       "17     concave points error    0.010300\n",
       "18           symmetry error    0.002488\n",
       "19  fractal dimension error    0.004129\n",
       "20             worst radius    0.091616\n",
       "21            worst texture    0.023959\n",
       "22          worst perimeter    0.140268\n",
       "23               worst area    0.109944\n",
       "24         worst smoothness    0.012964\n",
       "25        worst compactness    0.021098\n",
       "26          worst concavity    0.028202\n",
       "27     worst concave points    0.121761\n",
       "28           worst symmetry    0.010522\n",
       "29  worst fractal dimension    0.007382"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae13e7d4-f773-418e-ae5b-4e84f3d20113",
   "metadata": {},
   "source": [
    "### 24  Train a Random Forest Regressor and compare its performance with a single Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3467a98-50dc-45e5-9959-74111c4810af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy - 0.8261930533334777\n",
      "MSE :- 6468.263488271261\n"
     ]
    }
   ],
   "source": [
    "x,y=make_regression(n_samples=1000,n_features=10)  \n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=2)\n",
    "rf=RandomForestRegressor()\n",
    "rf.fit(x_train,y_train) \n",
    "y_pred=rf.predict(x_test)\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"Accuracy -\",r2_score(y_test,y_pred))\n",
    "print(\"MSE :-\",mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "163cc2f2-96ef-492c-adc1-36df875ec44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :- 0.4996790673902375\n",
      "MSE :- 18619.55280203362\n"
     ]
    }
   ],
   "source": [
    "dt=DecisionTreeRegressor() \n",
    "dt.fit(x_train,y_train)\n",
    "y_pred=dt.predict(x_test)\n",
    "print(\"Accuracy :-\",r2_score(y_test,y_pred)) \n",
    "print(\"MSE :-\",mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c69371-c0ea-4329-8ed3-a113e264ada0",
   "metadata": {},
   "source": [
    "### 25 Compute the Out-of-Bag (OOB) Score for a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da25ac19-e0a6-4c28-8332-a8c20ae622c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=make_classification(n_samples=1000,n_features=10,n_classes=2)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "899a3f98-6cd5-4d9c-bb71-56aa1fb401b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB SCORE :- 0.965\n"
     ]
    }
   ],
   "source": [
    "clf=RandomForestClassifier(n_estimators=100,oob_score=True)\n",
    "clf.fit(x_train,y_train) \n",
    "y_pred=clf.predict(x_test) \n",
    "oob=clf.oob_score_\n",
    "print(\"OOB SCORE :-\",oob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1453aa-1075-4850-ad0e-1de48f386320",
   "metadata": {},
   "source": [
    "### 26 Train a Bagging Classifier using SVM as a base estimator and print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "779fccee-1d18-488d-97c8-871e0fdd2f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=make_classification(n_samples=1000,n_features=10,n_classes=2)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b8d91a8-b5a5-455b-8e06-956cbf199d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC \n",
    "svm=SVC(kernel='linear')\n",
    "bg=BaggingClassifier(base_estimator=svm,n_estimators=100,random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9e66d33-2fc1-4846-9113-bd7baf950856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :- 0.915\n"
     ]
    }
   ],
   "source": [
    "bg.fit(x_train,y_train) \n",
    "y_pred=bg.predict(x_test) \n",
    "print(\"Accuracy :-\",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0860d468-7e25-42dd-a78c-9c3646168a95",
   "metadata": {},
   "source": [
    "### 27 Train a Random Forest Classifier with different numbers of trees and compare accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1546d6a2-b8d3-4793-85b9-dbca8462498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c471fe6f-2b5c-4ae3-bda7-e8ac33a5fba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trees: 10, Accuracy: 1.00\n",
      "Number of trees: 50, Accuracy: 1.00\n",
      "Number of trees: 100, Accuracy: 1.00\n",
      "Number of trees: 150, Accuracy: 1.00\n",
      "Number of trees: 200, Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "trees = [10, 50, 100, 150, 200]\n",
    "accuracies = []\n",
    "for i in trees:\n",
    "    rf = RandomForestClassifier(n_estimators=i, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"Number of trees: {i}, Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ca5018-ee87-4f78-a283-c92406ccdaf6",
   "metadata": {},
   "source": [
    "### 28  Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f051519-626f-4af3-9e40-8f6d07fe92d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "90ca9ba0-9e56-4c43-980b-b9031cc8b922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score of Bagging Classifier with Logistic Regression as base estimator: 0.96\n"
     ]
    }
   ],
   "source": [
    "x,y=make_classification(n_samples=1000,n_features=10,n_classes=2)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=2)\n",
    "lg=LogisticRegression() \n",
    "bg=BaggingClassifier(base_estimator=lg,n_estimators=100,random_state=42)\n",
    "bg.fit(x_train,y_train) \n",
    "y_pred=bg.predict(x_test) \n",
    "y_prob = bg.predict_proba(x_test)[:, 1]\n",
    "auc_score = roc_auc_score(y_test, y_prob)\n",
    "print(f\"AUC Score of Bagging Classifier with Logistic Regression as base estimator: {auc_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067c6003-4815-4b5e-b593-818c924f2e2c",
   "metadata": {},
   "source": [
    "### 29 Train a Random Forest Regressor and analyze feature importance scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e684dc0f-e9f6-4304-a574-ad17e8a409e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=make_regression(n_samples=1000,n_features=10)  \n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=2)\n",
    "rf=RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "53f636c8-4105-49e9-8549-3bc2b7da97a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance scores- [0.01732851 0.12972537 0.07011098 0.06712047 0.06197246 0.1515405\n",
      " 0.02482321 0.23301483 0.14995549 0.09440817]\n"
     ]
    }
   ],
   "source": [
    "rf.fit(x_train,y_train) \n",
    "y_pred=rf.predict(x_test) \n",
    "fi=rf.feature_importances_\n",
    "print(\"Feature importance scores-\",fi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93070526-8720-464e-b34d-7bfa3f5b817f",
   "metadata": {},
   "source": [
    "### 30 Train an ensemble model using both Bagging and Random Forest and compare accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "689595fc-af63-4fef-908f-658ffc62ede1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bagging Classifier: 1.00\n",
      "Accuracy of Random Forest Classifier: 1.00\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "base_estimator = DecisionTreeClassifier(random_state=42)\n",
    "bagging_classifier = BaggingClassifier(estimator=base_estimator, n_estimators=100, random_state=42)\n",
    "random_forest_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "bagging_classifier.fit(X_train, y_train)\n",
    "random_forest_classifier.fit(X_train, y_train)\n",
    "y_pred_bagging = bagging_classifier.predict(X_test)\n",
    "y_pred_rf = random_forest_classifier.predict(X_test)\n",
    "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
    "print(f\"Accuracy of Bagging Classifier: {accuracy_bagging:.2f}\")\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Accuracy of Random Forest Classifier: {accuracy_rf:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3e5d66-7dd9-4bdd-b660-9b27d87f3c94",
   "metadata": {},
   "source": [
    "### 31  Train a Random Forest Classifier and tune hyperparameters using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c88a496f-5327-4593-bc0c-7714085fa181",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78a46563-40cd-4180-adb0-221a39ad0bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier() \n",
    "rf.fit(X_train,y_train)\n",
    "y_pred=rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dfbb754-d89f-470b-a96b-e3c45addc29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without tuning:- 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy without tuning:-\",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54c2fd5c-498a-4645-bdbd-e6052a726d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'max_depth': [None, 10, 20, 30]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a69d6e6e-23c6-4d51-8b79-3ee341d60da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9963141-162e-4bcc-bc8e-887c50dc4a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid,\n",
    "                           cv=5, n_jobs=-1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8b3c29f-685c-47cf-81c1-be6128d79f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Best Parameters: {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 10}\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test)\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d0ea27-abe6-486e-867f-7987b38faf7a",
   "metadata": {},
   "source": [
    "### 32  Train a Bagging Regressor with different numbers of base estimators and compare performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "184d4203-ac0a-4cc9-b7d2-b7f66e1c8a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1627c5b3-4c75-422c-9ab2-9eef11806e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of estimators: 10, Accuracy: 1.00\n",
      "Number of estimators: 50, Accuracy: 1.00\n",
      "Number of estimators: 100, Accuracy: 1.00\n",
      "Number of estimators: 150, Accuracy: 1.00\n",
      "Number of estimators: 200, Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "estimators= [10, 50, 100, 150, 200]\n",
    "accuracies = []\n",
    "for i in estimators:\n",
    "    bg = BaggingRegressor(estimator=DecisionTreeRegressor(),n_estimators=i,random_state=42)\n",
    "    bg.fit(X_train, y_train)\n",
    "    y_pred = bg.predict(X_test)\n",
    "    accuracy = r2_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"Number of estimators: {i}, Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802dbd27-a94c-4ebe-b59e-ec4269b381f7",
   "metadata": {},
   "source": [
    "### 33 Train a Random Forest Classifier and analyze misclassified samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e69f0f09-036e-4725-854d-f6bfc57ab5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred = rf_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "518aecd6-92ae-4893-b731-07a5eed1fa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2317bba2-984c-489e-9448-b3bd3c24dc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      1.00      1.00         9\n",
      "   virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "Confusion Matrix:\n",
      " [[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "\n",
      "Misclassified Samples:\n",
      " Empty DataFrame\n",
      "Columns: [sepal length (cm), sepal width (cm), petal length (cm), petal width (cm), True Label, Predicted Label]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame for misclassified samples\n",
    "misclassified_df = pd.DataFrame(misclassified_samples, columns=iris.feature_names)\n",
    "misclassified_df['True Label'] = y_test[misclassified_indices]\n",
    "misclassified_df['Predicted Label'] = y_pred[misclassified_indices]\n",
    "\n",
    "# Display results\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=iris.target_names))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nMisclassified Samples:\\n\", misclassified_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7925dd-d30e-481d-9d7d-674206759a72",
   "metadata": {},
   "source": [
    "### 34 Train a Bagging Classifier and compare its performance with a single Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d26d8821-3b5c-4df3-a76a-e1c3f94e3d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "y_pred_dt = dt_classifier.predict(X_test)\n",
    "bagging_classifier = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42)\n",
    "bagging_classifier.fit(X_train, y_train)\n",
    "y_pred_bagging = bagging_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "59c2f9df-af86-4889-9aca-825b6a382eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree:  1.0\n",
      "Accuracy of Bagging Classifier: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Accuracy of Decision Tree: \",accuracy_score(y_test,y_pred))\n",
    "print(\"Accuracy of Bagging Classifier:\",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6767a8-427e-4dc1-a857-60d9b30968cd",
   "metadata": {},
   "source": [
    "### 35 Train a Random Forest Classifier and visualize the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d5fb2999-996c-4cec-b75f-37c088dc1902",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "rf=RandomForestClassifier()\n",
    "rf.fit(X_train,y_train) \n",
    "y_pred=rf.predict(X_test) \n",
    "cm=confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e25cbd09-5444-4e7a-ac73-2a0f99d0ae26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "sns.heatmap(cm,annot=True,xticklabels=iris.target_names,yticklabels=iris.target_names) \n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c12ef58-61f9-458f-b647-486265f19a13",
   "metadata": {},
   "source": [
    "### 36 Train a Stacking Classifier using Decision Trees, SVM, and Logistic Regression, and compare accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ae4f8504-ec6b-4b5c-9ac9-650a1dc7bc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier \n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c95facb3-63d1-476a-9a2c-698931127011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(estimators=[(&#x27;dt&#x27;, DecisionTreeClassifier(random_state=42)),\n",
       "                               (&#x27;svm&#x27;, SVC(probability=True, random_state=42)),\n",
       "                               (&#x27;logistic&#x27;,\n",
       "                                LogisticRegression(max_iter=200,\n",
       "                                                   random_state=42))],\n",
       "                   final_estimator=LogisticRegression())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StackingClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.StackingClassifier.html\">?<span>Documentation for StackingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>StackingClassifier(estimators=[(&#x27;dt&#x27;, DecisionTreeClassifier(random_state=42)),\n",
       "                               (&#x27;svm&#x27;, SVC(probability=True, random_state=42)),\n",
       "                               (&#x27;logistic&#x27;,\n",
       "                                LogisticRegression(max_iter=200,\n",
       "                                                   random_state=42))],\n",
       "                   final_estimator=LogisticRegression())</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>dt</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DecisionTreeClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(random_state=42)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>svm</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SVC</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(probability=True, random_state=42)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>logistic</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=200, random_state=42)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingClassifier(estimators=[('dt', DecisionTreeClassifier(random_state=42)),\n",
       "                               ('svm', SVC(probability=True, random_state=42)),\n",
       "                               ('logistic',\n",
       "                                LogisticRegression(max_iter=200,\n",
       "                                                   random_state=42))],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "svm_classifier = SVC(probability=True, random_state=42)\n",
    "logistic_classifier = LogisticRegression(max_iter=200, random_state=42)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "logistic_classifier.fit(X_train, y_train)\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[('dt', dt_classifier), \n",
    "                ('svm', svm_classifier), \n",
    "                ('logistic', logistic_classifier)],\n",
    "    final_estimator=LogisticRegression()\n",
    ")\n",
    "stacking_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f419ffb6-50d1-457c-8bef-f80d716dd6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree: 1.0000\n",
      "Accuracy of SVM: 1.0000\n",
      "Accuracy of Logistic Regression: 1.0000\n",
      "Accuracy of Stacking Classifier: 1.0000\n"
     ]
    }
   ],
   "source": [
    "y_pred_dt = dt_classifier.predict(X_test)\n",
    "y_pred_svm = svm_classifier.predict(X_test)\n",
    "y_pred_logistic = logistic_classifier.predict(X_test)\n",
    "y_pred_stacking = stacking_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracies\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "accuracy_logistic = accuracy_score(y_test, y_pred_logistic)\n",
    "accuracy_stacking = accuracy_score(y_test, y_pred_stacking)\n",
    "\n",
    "# Print accuracies\n",
    "print(f\"Accuracy of Decision Tree: {accuracy_dt:.4f}\")\n",
    "print(f\"Accuracy of SVM: {accuracy_svm:.4f}\")\n",
    "print(f\"Accuracy of Logistic Regression: {accuracy_logistic:.4f}\")\n",
    "print(f\"Accuracy of Stacking Classifier: {accuracy_stacking:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3d6cbd-4096-43da-925b-d67723ffd521",
   "metadata": {},
   "source": [
    "### 37 Train a Random Forest Classifier and print the top 5 most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d52d98b5-046c-4589-a000-4c2e83bf1c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Most Important Features:\n",
      "             Feature  Importance\n",
      "2  petal length (cm)    0.439994\n",
      "3   petal width (cm)    0.421522\n",
      "0  sepal length (cm)    0.108098\n",
      "1   sepal width (cm)    0.030387\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "feature_names = iris.feature_names\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "importances = rf_classifier.feature_importances_\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "})\n",
    "\n",
    "feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "print(\"Top 5 Most Important Features:\")\n",
    "print(feature_importances_df.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf615ea2-e904-42b5-ba55-76a200bdcee9",
   "metadata": {},
   "source": [
    "### 38 Train a Bagging Classifier and evaluate performance using Precision, Recall, and F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a5ee7265-98b7-4252-a0f5-9bab7367c2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      1.00      1.00         9\n",
      "   virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "base_dt = DecisionTreeClassifier(random_state=42)\n",
    "bagging_clf = BaggingClassifier(estimator=base_dt, n_estimators=50, random_state=42)\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "y_pred = bagging_clf.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830c0035-40ba-4927-86d6-fe301eeb91a5",
   "metadata": {},
   "source": [
    "### 39 Train a Random Forest Classifier and analyze the effect of max_depth on accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5d013be8-8608-43e7-9e37-6fc3d45c3b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth vs Accuracy:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  accuracy\n",
       "0          1       1.0\n",
       "1          2       1.0\n",
       "2          3       1.0\n",
       "3          4       1.0\n",
       "4          5       1.0\n",
       "5          6       1.0\n",
       "6          7       1.0\n",
       "7          8       1.0\n",
       "8          9       1.0\n",
       "9         10       1.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "max_depths = list(range(1, 11)) \n",
    "accuracies = []\n",
    "for max_depth in max_depths:\n",
    "    rf_classifier = RandomForestClassifier(max_depth=max_depth, random_state=42)\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "results_df = pd.DataFrame({'max_depth': max_depths, 'accuracy': accuracies})\n",
    "print(\"Max Depth vs Accuracy:\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9d5a69-cef3-4f64-8010-09d5d83167c9",
   "metadata": {},
   "source": [
    "### 40  Train a Bagging Regressor using different base estimators (DecisionTree and KNeighbors) and compare performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a4c7187d-ca10-4044-b4a6-4d05b6ee73c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1af46a44-3b8c-42e2-ab6a-708f48b9209e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base Estimator</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.003228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>0.031208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Base Estimator  Mean Squared Error\n",
       "0   DecisionTree            0.003228\n",
       "1     KNeighbors            0.031208"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.data[:, 2] \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "base_estimators = {\n",
    "    'DecisionTree': DecisionTreeRegressor(random_state=42),\n",
    "    'KNeighbors': KNeighborsRegressor(n_neighbors=5)\n",
    "}\n",
    "performances = {}\n",
    "for name, estimator in base_estimators.items():\n",
    "    bagging_regressor = BaggingRegressor(estimator=estimator, n_estimators=50, random_state=42)\n",
    "    bagging_regressor.fit(X_train, y_train)\n",
    "    y_pred = bagging_regressor.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    performances[name] = mse\n",
    "results_df = pd.DataFrame(list(performances.items()), columns=['Base Estimator', 'Mean Squared Error'])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2abb420-48f1-4768-b697-106e54cda065",
   "metadata": {},
   "source": [
    "### 41 Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8ae2b46f-6060-4014-a2b6-9ec6acdfc793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "y_binary = (y == 0).astype(int) \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_proba = rf_classifier.predict_proba(X_test)[:, 1]\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5891aae2-5dd1-4807-94d8-94d425e6e023",
   "metadata": {},
   "source": [
    "### 42 Train a Bagging Classifier and evaluate its performance using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9dd4e9ef-720e-442a-a28a-18ca3def6983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0b115106-81ae-4b86-be28-e6c5c1da7ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.96666667 0.96666667 0.93333333 0.96666667 1.        ]\n",
      "Mean Cross-Validation Accuracy: 0.9667\n",
      "Test Set Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "base_estimator = DecisionTreeClassifier(random_state=42)\n",
    "bagging_classifier = BaggingClassifier(estimator=base_estimator, n_estimators=50, random_state=42)\n",
    "cv_scores = cross_val_score(bagging_classifier, X, y, cv=5)\n",
    "print(f\"Cross-Validation Accuracy Scores: {cv_scores}\")\n",
    "print(f\"Mean Cross-Validation Accuracy: {np.mean(cv_scores):.4f}\")\n",
    "bagging_classifier.fit(X_train, y_train)\n",
    "y_pred = bagging_classifier.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Set Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2071d3-65c0-4556-94c0-f39d1aedbac7",
   "metadata": {},
   "source": [
    "### 43 Train a Random Forest Classifier and plot the Precision-Recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "79c6b5b2-0f94-452b-a5f3-72d97f78a379",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "610f1a37-85cb-4e0d-a58e-1e749fda3c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "y_binary = (y == 0).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_proba = rf_classifier.predict_proba(X_test)[:, 1]  \n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "plt.plot(recall, precision, marker='o')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dd4c3c-5ac6-467a-93ad-c2fc414a63b9",
   "metadata": {},
   "source": [
    "### 44 Train a Stacking Classifier with Random Forest and Logistic Regression and compare accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d611e917-124e-445b-9add-ea4c34c3be82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Accuracy: 1.0000\n",
      "Random Forest Classifier Accuracy: 1.0000\n",
      "Logistic Regression Classifier Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "base_estimators = [\n",
    "    ('rf', RandomForestClassifier(random_state=42)),\n",
    "    ('lr', LogisticRegression(max_iter=200, random_state=42))\n",
    "]\n",
    "stacking_classifier = StackingClassifier(estimators=base_estimators, final_estimator=LogisticRegression())\n",
    "stacking_classifier.fit(X_train, y_train)\n",
    "y_pred_stacking = stacking_classifier.predict(X_test)\n",
    "accuracy_stacking = accuracy_score(y_test, y_pred_stacking)\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "lr_classifier = LogisticRegression(max_iter=200, random_state=42)\n",
    "lr_classifier.fit(X_train, y_train)\n",
    "y_pred_lr = lr_classifier.predict(X_test)\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Stacking Classifier Accuracy: {accuracy_stacking:.4f}\")\n",
    "print(f\"Random Forest Classifier Accuracy: {accuracy_rf:.4f}\")\n",
    "print(f\"Logistic Regression Classifier Accuracy: {accuracy_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d721d26-fd39-46f1-bdeb-d72397e5e136",
   "metadata": {},
   "source": [
    "### 45 Train a Bagging Regressor with different levels of bootstrap samples and compare performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "735e1799-745a-4d3a-92c4-97ef5f7fbcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2df574f8-a414-4e23-937c-d660543e5f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "results = []\n",
    "bootstrap_fractions = [0.1, 0.5, 1.0]\n",
    "\n",
    "for fraction in bootstrap_fractions:\n",
    "    bagging_classifier = BaggingClassifier(\n",
    "        estimator=DecisionTreeClassifier(),\n",
    "        n_estimators=100,\n",
    "        max_samples=fraction,\n",
    "        random_state=42)\n",
    "    bagging_classifier.fit(X_train, y_train)\n",
    "    y_pred = bagging_classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results.append((fraction, accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7d998698-e209-4045-8104-89fc7482e228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Samples Fraction: 0.1, Accuracy: 0.9649\n",
      "Max Samples Fraction: 0.5, Accuracy: 0.9561\n",
      "Max Samples Fraction: 1.0, Accuracy: 0.9561\n"
     ]
    }
   ],
   "source": [
    "for fraction, accuracy in results:\n",
    "    print(f\"Max Samples Fraction: {fraction}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5915e08-05b4-4511-aeb2-d832503ef12b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
