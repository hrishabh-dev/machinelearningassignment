{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "309ad6a2-0bf4-447b-be10-3350aedc03e5",
   "metadata": {},
   "source": [
    "### 1- What is a parameter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6c951ec-18c1-44f6-9d19-9c9e3e53e913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b27119-9a56-428e-a81b-b417f28c8983",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "parameters can also refer to the arguments that are passed to functions or methods.\n",
    "\n",
    "Parameters are the internal variables that a machine learning model learns from the training data.\n",
    "\n",
    "For example, in a linear regression model, the coefficients (weights) assigned to each \n",
    "feature (input variable) are considered parameters.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6d0852-11c7-4daf-918f-75f341c4d087",
   "metadata": {},
   "source": [
    "### 2- What is correlation? What does negative correlation mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc412b07-cb6d-4d65-8bf5-a66535ae4806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35866c9f-c3b7-4366-a0a1-b824a5d6193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Correlation is a statistical measure that describes the degree to which two variables move\n",
    "   in relation to one another. \n",
    "\n",
    "   it ranges from -1 to 1.\n",
    "\n",
    "   A correlation of 1 indicates a perfect positive correlation\n",
    "   \n",
    "   A correlation of -1 indicates a perfect negative correlation\n",
    "   \n",
    "   A correlation of 0 indicates no correlation\n",
    "\n",
    "\n",
    "\n",
    "Negative correlation refers to a situation where an increase in one variable is associated with\n",
    "a decrease in another variable.\n",
    "\n",
    "for example-\n",
    "If variable X increases while variable Y decreases, this indicates a negative correlation \n",
    "between X and Y.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa85ff77-4fa0-471d-bce0-9005041e8e2f",
   "metadata": {},
   "source": [
    "### 3-Define Machine Learning. What are the main components in Machine Learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e927327-0a40-4c54-861d-8d6d26213065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3732aad-c952-41d4-a906-974fc3c49533",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Machine Learning :- is a subset of artificial intelligence (AI) it  that focuses on the \n",
    "development of algorithms and statistical models that enable computers to \n",
    "perform specific tasks without being explicitly programmed.\n",
    "\n",
    " ML algorithms learn from and make predictions based on data.\n",
    "\n",
    " Main Components:-\n",
    "\n",
    " . Data\n",
    "\n",
    " . Features\n",
    "\n",
    " . Model\n",
    "\n",
    " . Algorithem\n",
    "\n",
    " . Training\n",
    "\n",
    " . Evaluation\n",
    "\n",
    " . Prediction \n",
    "\n",
    " \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da6b7c7-5a47-4dca-8200-954415736128",
   "metadata": {},
   "source": [
    "### 4- How does loss value help in determining whether the model is good or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cd5a343-4380-4f88-be92-63355fc50543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21319847-de8d-44b6-890b-f7e5832e2b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The loss value  is a  metrics that quantifies how well a model's predictions\n",
    "align with the actual target values.\n",
    "\n",
    "It serves as a numerical measure of the model's performance during training and evaluation\n",
    "\n",
    "It helps in several ways :-\n",
    "\n",
    "1- Quantifying Model Performance\n",
    "2- Training Process Optimization\n",
    "3- Comparison of Different Models\n",
    "4- Decision-Making\n",
    "\n",
    "Common loss functions include Mean Squared Error (MSE) and Mean Absolute Error (MAE)\n",
    "It evaluate the error between predicted and actual continuous values.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d3c26f-44af-4a87-8653-605e9dfb0bdb",
   "metadata": {},
   "source": [
    "### 5-What are continuous and categorical variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd668dbd-a099-4b55-a198-bd0ee47e17de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e64dd7-78f0-4cde-a99c-9add9ee49e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Continuous :-  \n",
    "\n",
    "Continuous variables are numerical variables that can take an infinite number \n",
    "of values within a given range.\n",
    "\n",
    "example:- height, weight, temperature, and time are all continuous variables\n",
    "\n",
    "Categorical variable :-\n",
    "\n",
    "Categorical variables are variables that take on a limited, fixed number of \n",
    "possible values (categories) and represent qualitative data.\n",
    "\n",
    "Categorical variables consist of distinct groups \n",
    "\n",
    "example:- Gender ,Marital Status ,Types of Animals \n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b2743d-bd07-497c-8fcb-a46be5b9e374",
   "metadata": {},
   "source": [
    "### 6 How do we handle categorical variables in Machine Learning? What are the common techniques?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bbafb6a-3363-41ae-8e66-53127dac4589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bc0fd9-b1a3-4632-bcbb-acb77bd40de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Categorical variables can significantly influence a model's performance, and \n",
    "various techniques exist for transforming these variables into a suitable format.\n",
    "\n",
    "\n",
    "some common techniques:\n",
    "\n",
    "1. Label Encoding\n",
    "involves converting categorical labels into numerical values. \n",
    "Each category is assigned a unique integer\n",
    "\n",
    "\n",
    "2. One-Hot Encoding\n",
    "involves creating binary (0 or 1) columns for each category in the original variable.\n",
    "\n",
    "\n",
    "3. Binary Encoding\n",
    "Binary encoding is a hybrid approach that first converts categories to integers (like label encoding) \n",
    "and then converts those integers to binary code.\n",
    "\n",
    "\n",
    "4. Mean Encoding\n",
    "involves replacing each category with the mean of the target variable for that category. \n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8ff765-0350-49ec-9384-87964c1679a7",
   "metadata": {},
   "source": [
    "### 7-What do you mean by training and testing a dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42576bbf-bde3-44d2-986a-220c489dd920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b248916e-1b3d-4de2-a0f6-81316c7eb6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Training Dataset:-\n",
    "\n",
    "The training dataset is a subset of the data used to train a machine learning model.\n",
    "During the training phase, the model learns patterns, relationships, and structures\n",
    "from this dataset.\n",
    "\n",
    ".goal of using a training dataset is to allow the model to learn from the input\n",
    "features (independent variables) and the corresponding target outcomes (dependent variable)\n",
    "\n",
    "Testing Dataset:-\n",
    "\n",
    " It is reserved for evaluating the performance of the model after it has been trained.\n",
    " .a testing dataset is used to assess how well the model generalizes to new, unseen data.\n",
    "\n",
    " it is tested on the testing dataset to see how accurately it can make predictions.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2576a5fe-c334-46fd-bf74-471bf50e0ba5",
   "metadata": {},
   "source": [
    "### 8 What is sklearn.preprocessing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e826e515-1211-4336-98fc-173e9907cae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82624f49-7349-43b8-833b-c2ea86d0d31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "sklearn.preprocessing is a module in the Python library Scikit-learn\n",
    "it has many tools for preprocessing data prior to training machine learning models\n",
    "\n",
    "\n",
    "preprocessing includes scaling, transforming, encoding, and normalizing data\n",
    "\n",
    "\n",
    "It provides a variety of  functions that help transform and scale data \n",
    " appropriately and generate new features that can improve model performance\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdc111f-fbeb-4897-9e32-39e20f052bbf",
   "metadata": {},
   "source": [
    "### 9 What is a Test set?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d53b5f5-e11b-46ec-bd37-8628125f34c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solutin :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d557eb0-b5cb-44cf-9ca3-6ad842b49920",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "A test set is  used to evaluate the performance of a machine learning model\n",
    "after it has been trained.\n",
    "\n",
    "\n",
    " The main purpose of a test set is to validate the model's ability to generalize.\n",
    "\n",
    "\n",
    " It helps determine whether the insights gainedduring training can be applied \n",
    " effectively to unseen data.\n",
    " \n",
    "\n",
    " The performance on the test set can guide model selection and hyperparameter tuning decisions\n",
    " \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc38bc9-94d2-43f3-9427-844b9871010d",
   "metadata": {},
   "source": [
    "### 10 How do we split data for model fitting (training and testing) in Python?How do you approach a Machine Learning problem?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "305a828f-7f99-4186-992c-49599229f5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4da0266-a46e-4cb3-b4e1-1a3b36ef1b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "In Python,  to split data into training and testing sets is by using the\n",
    "train_test_split function from the sklearn.model_selection module\n",
    "'''\n",
    "# here is a sample :-\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Assuming your features are in 'X' and target in 'y'\n",
    "X = data.drop('target_column', axis=1)\n",
    "y = data['target_column']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d64263-04c5-4e2a-978e-6641d1cd21e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "approach to tackling a machine learning problem  involves the following steps:\n",
    "\n",
    "1- Define the Problem\n",
    "\n",
    "2- Collect Data\n",
    "\n",
    "3- Explore Data\n",
    "\n",
    "4- Preprocess Data\n",
    "\n",
    "5- Train the Model\n",
    "\n",
    "6- Evaluate the Model\n",
    "\n",
    "By following these structured steps, you can systematically approach and tackle\n",
    "machine learning problems effectively\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb43c4c0-2337-4705-8138-5050787769cc",
   "metadata": {},
   "source": [
    "### 11- Why do we have to perform EDA before fitting a model to the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "402f2993-3454-40aa-98cf-cf94b93c6463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688ab407-9dd6-41c5-9e2e-9e7fdf919a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    ".EDA helps identify the types of data (numerical, categorical, ordinal, etc.) in the dataset.\n",
    "\n",
    "\n",
    ".EDA allows you to discover missing and null values in the dataset. Understanding the extent and\n",
    "pattern of missingness is essential for deciding how to handle them\n",
    "\n",
    "\n",
    ". EDA helps identify these outliers so that you can decide how to handle them \n",
    "\n",
    "\n",
    ". EDA helps in understanding relationships between features and the target variable, which is \n",
    " essential for feature selection and engineering\n",
    "\n",
    "\n",
    ". Different algorithms have underlying assumptions (e.g., linearity in linear regression).\n",
    "\n",
    ". EDA can help validate whether these assumptions hold for your data.\n",
    "\n",
    "\n",
    " \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d9384e-465f-4ee2-9717-d4c7dc67a9b5",
   "metadata": {},
   "source": [
    "### 12 What is correlation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1a146e2-9cac-402b-8c26-874b01e28da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81399e6-de0b-4c53-a7fe-2d37bb938ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "\n",
    "Correlation is a statistical measure that describes the degree to which two variables move\n",
    "   in relation to one another. \n",
    "\n",
    "   it ranges from -1 to 1.\n",
    "\n",
    "   A correlation of 1 indicates a perfect positive correlation\n",
    "   \n",
    "   A correlation of -1 indicates a perfect negative correlation\n",
    "   \n",
    "   A correlation of 0 indicates no correlation\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b77553-e08b-4d80-913b-829dd751eb5d",
   "metadata": {},
   "source": [
    "### 13 What does negative correlation mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e99a2e2-b2c4-4585-9c9b-dc5bbb51bd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d5fa7b-1d61-47c7-97da-4430e6c8a5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Negative correlation refers to a situation where an increase in one variable is associated with\n",
    "a decrease in another variable.\n",
    "\n",
    "for example-\n",
    "If variable X increases while variable Y decreases, this indicates a negative correlation \n",
    "between X and Y.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3466ee6d-23ac-46f2-819f-b1bccfd7de0e",
   "metadata": {},
   "source": [
    "### 14 How can you find correlation between variables in Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddae2028-20dc-49ac-bd22-1f27da8ff3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44596fe8-40a1-4e45-84a2-aefa51becc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Finding the correlation between variables in Python can be\n",
    "done using various libraries, most notably pandas and numpy\n",
    "\n",
    "The pandas DataFrame provides a convenient corr() method to compute the\n",
    "correlation matrix for all numerical columns in the DataFrame.\n",
    "\n",
    "\n",
    "'''\n",
    "# here is a example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17b59928-2e4e-4979-876d-89b4cb2ab7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C\n",
      "A  1.0 -1.0  1.0\n",
      "B -1.0  1.0 -1.0\n",
      "C  1.0 -1.0  1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {\n",
    "    'A': [1, 2, 3, 4, 5],\n",
    "    'B': [5, 4, 3, 2, 1],\n",
    "    'C': [2, 3, 4, 5, 6],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cb0fac-794d-4217-b5c3-1e6a20d67fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "If you need to compute the correlation between two specific NumPy arrays,\n",
    "you can use numpy.corrcoef().\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5df087f-cbaa-4f5e-81cf-04b2dc31d0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Coefficient between x and y: -0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([5, 4, 3, 2, 1])\n",
    "\n",
    "# Calculate correlation coefficient\n",
    "correlation_coefficient = np.corrcoef(x, y)[0, 1]\n",
    "\n",
    "print(f'Correlation Coefficient between x and y: {correlation_coefficient}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02da32d7-1476-43ca-af20-9c80545ec25a",
   "metadata": {},
   "source": [
    "### 15 What is causation? Explain difference between correlation and causation with an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b5bb8c7-5c9b-47bf-8ec0-0cd517404302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5be8fac-70a5-4f3d-9d09-b2847190ae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    ". Causation refers to a relationship between two events or variables where one event \n",
    "(the cause) directly influences or brings about the other event (the effect).\n",
    "\n",
    "causation implies that changes in one variable will lead to changes in another variable. \n",
    "\n",
    "\n",
    ".  correlation is a statistical measure expressing the extent to which two variables \n",
    "change together.\n",
    "A correlation between two variables does not imply that one variable causes the other to change; \n",
    "they may be related due to external factors or simply by chance.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bc2c70-e7eb-48ee-a30e-0aaa161d19ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Causation: Has a clear direction.\n",
    "Correlation: Can be positive, negative, or zero,\n",
    "\n",
    "for example :-\n",
    "\n",
    " if there is a strong positive correlation between ice cream sales and the number \n",
    " of people who go swimming. \n",
    " if  ice cream sales increase, the number of people swimming also increases.\n",
    "\n",
    "\n",
    " if we have data showing that increasing the amount of exercise leads to decreased body weight,\n",
    " we can conclude that there is a causal relationship here: exercise (the cause) leads to weight \n",
    " loss\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b49a80-984d-471b-a326-4b0db21e6667",
   "metadata": {},
   "source": [
    "### 16 What is an Optimizer? What are different types of optimizers? Explain each with an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70cbe402-1eef-413f-a72c-51db671dce92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86efb47-463a-4034-b6d8-2d2bffd951ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "An optimizer is an algorithm or technique used to find the best possible solution\n",
    "from a set of possible solutions.\n",
    "\n",
    " Optimizers are used in various fields, including mathematics, computer science, economics,\n",
    " and machine learning. \n",
    "\n",
    "\n",
    " Types of Optimizers:\n",
    "\n",
    " 1. Gradient Descent (GD)\n",
    "  is an iterative optimization algorithm that finds the minimum of a function by following the \n",
    "  negative gradient of the function.\n",
    "\n",
    " 2-Stochastic Gradient Descent (SGD)\n",
    " Stochastic Gradient Descent is a variant of Gradient Descent that uses a single example from the\n",
    " training set to compute the gradient at each iteration.\n",
    "\n",
    " 3. Conjugate Gradient (CG)\n",
    " Conjugate Gradient is an optimization algorithm that uses the concept of conjugate directions\n",
    " to find the minimum of a function.\n",
    "\n",
    " 4. Quasi-Newton Methods (BFGS)\n",
    "\n",
    " Quasi-Newton Methods, such as BFGS, are optimization algorithms that use an approximation of the\n",
    " Hessian matrix to find the minimum of a function.\n",
    "\n",
    " \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74a5293-71b1-41c1-8f68-e3e9cded1d99",
   "metadata": {},
   "source": [
    "### f(x)=(x−2)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7230dfe5-4fdb-4e1c-80e2-818944c20fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum at x = 1.976941569907863, f(x) = 0.000531691198313971\n"
     ]
    }
   ],
   "source": [
    " # 1- Gradient Descent\n",
    "def f(x):\n",
    "    return (x - 2)**2\n",
    "def df(x):\n",
    "    return 2 * (x - 2)\n",
    "x = 0.0  \n",
    "lr = 0.1\n",
    "for _ in range(20):  \n",
    "    x -= lr * df(x)\n",
    "\n",
    "print(f\"Minimum at x = {x}, f(x) = {f(x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84840295-d167-498a-90b5-33bf14be2d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum at x = 1.976941569907863, f(x) = 0.000531691198313971\n"
     ]
    }
   ],
   "source": [
    "# 2. Stochastic Gradient Descent (SGD)\n",
    "def f(x):\n",
    "    return (x - 2)**2\n",
    "def df(x):\n",
    "    return 2 * (x - 2)\n",
    "x = 0.0\n",
    "lr = 0.1\n",
    "for _ in range(20):  \n",
    "    gradient = df(x)  \n",
    "    x -= lr* gradient  \n",
    "print(f\"Minimum at x = {x}, f(x) = {f(x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fabfbde-14fc-4473-abbe-5b4bd50b4a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum at x = -1.0, f(x) = 9.0\n"
     ]
    }
   ],
   "source": [
    "# 3. Conjugate Gradient (CG)\n",
    "def f(x):\n",
    "    return (x - 2)**2\n",
    "def df(x):\n",
    "    return 2 * (x - 2)\n",
    "x = 5.0  \n",
    "gradient = df(x)\n",
    "x -= gradient \n",
    "print(f\"Minimum at x = {x}, f(x) = {f(x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4ca1699-66c2-4162-a0a0-00a0c0fabf5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum at x = 4.4, f(x) = 5.760000000000002\n"
     ]
    }
   ],
   "source": [
    "# 4 Quasi-Newton Method (BFGS)\n",
    "def f(x):\n",
    "    return (x - 2)**2\n",
    "def df(x):\n",
    "    return 2 * (x - 2)\n",
    "x = 5.0 \n",
    "lr = 0.1\n",
    "H = 1.0  \n",
    "for _ in range(1): \n",
    "    gradient = df(x)\n",
    "    x_new = x - lr * H * gradient  \n",
    "    x = x_new  \n",
    "print(f\"Minimum at x = {x}, f(x) = {f(x)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc38934-5e77-4998-be7e-69fcdfda2129",
   "metadata": {},
   "source": [
    "### 17 What is sklearn.linear_model ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f1e5efd-6dd5-4b85-bed1-830aaaf04d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087e918c-be1e-431e-b1ee-47aaa47939de",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "sklearn.linear_model is a module in the  Python library scikit-learn \n",
    "\n",
    " It provides a variety of algorithms for linear regression and classification. \n",
    " \n",
    "Linear models assume a linear relationship between the input features and the target variable,\n",
    "making them  powerful tools for predictive modeling.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f18482-23b1-4898-83d0-78aa51b5d1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)  # Fit the model\n",
    "predictions = model.predict(X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d50444-e2ba-447d-9cfe-c055ac5578e6",
   "metadata": {},
   "source": [
    "### 18 What does model.fit() do? What arguments must be given?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e33169f-a228-43ec-a1a5-be8ff27c2543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc3d009-a6e9-4f0b-bcab-47706b33b7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model.fit() - It updates the model's parameters to best fit the training data.\n",
    "\n",
    "              Then Fits the model to the data\n",
    "              \n",
    "               It computes metrics like accuracy, precision, recall, etc.,\n",
    "               depending on the type of model and problem.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e5bb0b-56a7-4627-acd4-235a359103a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Required arguments for model.fit():\n",
    "\n",
    "X : The feature data used to train the model.\n",
    "\n",
    "y ( target): The target variable.\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b019faab-696a-486d-a079-2397723c8e58",
   "metadata": {},
   "source": [
    "### 19 What does model.predict() do? What arguments must be given?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2063642-d17f-48d5-955f-4fb3c1866189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4a4c95-b24e-4063-b0ce-7ca08ed7f42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "The model.predict() method in scikit-learn is used to make\n",
    "predictions based on a trained machine learning model.\n",
    "\n",
    "Generates Predictions: It takes in new input data and computes the output \n",
    "\n",
    "Returns the predicted labels or values\n",
    "\n",
    "\n",
    "Required arguments for model.predict():\n",
    "\n",
    "X: The input data that you want to predict. \n",
    "\n",
    "It should have the same number of features (columns) as the data used to train the model.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755e9096-5d1e-4ff6-b055-0f5514de6ae0",
   "metadata": {},
   "source": [
    "### 20 What are continuous and categorical variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0591a64-d0a9-400b-9ff4-3210a541a427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1334b6-6c8c-44b9-8843-deb395ce8bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Continuous :-  \n",
    "\n",
    "Continuous variables are numerical variables that can take an infinite number \n",
    "of values within a given range.\n",
    "\n",
    "example:- height, weight, temperature, and time are all continuous variables\n",
    "\n",
    "Categorical variable :-\n",
    "\n",
    "Categorical variables are variables that take on a limited, fixed number of \n",
    "possible values (categories) and represent qualitative data.\n",
    "\n",
    "Categorical variables consist of distinct groups \n",
    "\n",
    "example:- Gender ,Marital Status ,Types of Animals \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11af8e99-2faa-4c19-ba9c-5553eb78c474",
   "metadata": {},
   "source": [
    "### 21 What is feature scaling? How does it help in Machine Learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f7ea64f-7efe-4860-9782-81f78c8dfca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbcfbcd-9045-4cc6-9771-a38a729b9a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Feature scaling is a method used to normalize or standardize the range\n",
    "of independent variables (features) in a dataset\n",
    "\n",
    " primary purpose is to ensure that each feature contributes equally to the distance calculations\n",
    "\n",
    " \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88703e5d-5c22-4b9e-9314-26dbbbb42c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Improves convergence :-\n",
    "\n",
    "For algorithms that use optimization techniques (e.g. gradient descent), \n",
    "having features on similar scales can lead to faster convergence.\n",
    "\n",
    "Better performance: -\n",
    "\n",
    "Feature scaling can improve the performance of models, leading to better prediction\n",
    "accuracy and stability.\n",
    "\n",
    "Equal Importance: -\n",
    "\n",
    " Feature scaling ensures that all features contribute equally to distance calculations.\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a19460-04b3-47f0-b5d8-585429d2d6f7",
   "metadata": {},
   "source": [
    "### 22 How do we perform scaling in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8e0abce-4bd6-4428-be67-37c7b607cf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aca76b-a0a2-417f-90a6-e7881385071c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "scaling (feature scaling) can be performed easily with libraries like scikit-learn\n",
    "\n",
    "It  include StandardScaler, MinMaxScaler\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85e8ddea-2462-4f97-8fa7-e275b0c2822c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled data (StandardScaler):\n",
      "[[-1.34164079 -1.34164079]\n",
      " [-0.4472136  -0.4472136 ]\n",
      " [ 0.4472136   0.4472136 ]\n",
      " [ 1.34164079  1.34164079]]\n"
     ]
    }
   ],
   "source": [
    "# example of standard scaler\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data = np.array([[1, 2000],\n",
    "                 [2, 3000],\n",
    "                 [3, 4000],\n",
    "                 [4, 5000]])\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "print(\"Scaled data (StandardScaler):\")\n",
    "print(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b311b4ab-ba1e-4e31-946f-83fdc881976c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled data (MinMaxScaler):\n",
      "[[0.         0.        ]\n",
      " [0.33333333 0.33333333]\n",
      " [0.66666667 0.66666667]\n",
      " [1.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# example of minmax scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "data = np.array([[1, 2000],\n",
    "                 [2, 3000],\n",
    "                 [3, 4000],\n",
    "                 [4, 5000]])\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "print(\"Scaled data (MinMaxScaler):\")\n",
    "print(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9080204-a10c-405a-aaf3-2577136fd7f8",
   "metadata": {},
   "source": [
    "### 23 What is sklearn.preprocessing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f944507f-3cae-44c5-baa7-679d6b076788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee582e6-bd67-4873-8943-02dddf1f79c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "sklearn.preprocessing is a module in the Python library Scikit-learn\n",
    "it has many tools for preprocessing data prior to training machine learning models\n",
    "\n",
    "\n",
    "preprocessing includes scaling, transforming, encoding, and normalizing data\n",
    "\n",
    "\n",
    "It provides a variety of  functions that help transform and scale data \n",
    " appropriately and generate new features that can improve model performance\n",
    " '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3212febd-5f7e-4fac-99f0-11c513ccbaf2",
   "metadata": {},
   "source": [
    "### 24 How do we split data for model fitting (training and testing) in Python?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bced8e11-03a5-4a68-80f5-9f6d1c31f8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4174508-326c-42b7-9ec6-a340fe803691",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "In Python,  to split data into training and testing sets is by using the\n",
    "train_test_split function from the sklearn.model_selection module\n",
    "'''\n",
    "# here is a sample :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c28c750-0065-4511-ab2d-dd039f44912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Assuming your features are in 'X' and target in 'y'\n",
    "X = data.drop('target_column', axis=1)\n",
    "y = data['target_column']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedd87ef-1559-4d20-b11c-372f212669d1",
   "metadata": {},
   "source": [
    "### 25 Explain data encoding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfd5dc7f-348c-4ddf-a204-6d234fff1e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3673025-71ba-47aa-99d5-82ede79dc64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Data encoding is the process of converting categorical data into a numerical format\n",
    "\n",
    "\n",
    "many machine learning models require input features to be in a numerical format. \n",
    "\n",
    "\n",
    "f categorical data is left as text, some models may misinterpret the values\n",
    "(e.g., treating \"red,\" \"blue,\" and \"green\" as ordinal values rather than nominal categories).\n",
    "\n",
    "\n",
    "Properly encoded data can enhance the performance and accuracy of machine learning models.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe66707-d572-445e-b441-dfd94980c1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Methods of Data Encoding\n",
    "\n",
    "1-Label Encoding:\n",
    "\n",
    "Each unique category is assigned an integer value\n",
    "\n",
    "2-One-Hot Encoding:\n",
    "\n",
    "Creates a new binary column for each category, representing the presence (1) or absence (0) \n",
    "\n",
    "Ordinal Encoding:\n",
    "\n",
    "Similar to label encoding, but used specifically for ordinal categorical variables \n",
    "that have a defined order.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf35cd5-5b7d-4552-a517-15dd5367ba20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
